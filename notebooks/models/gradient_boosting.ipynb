{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    average_precision_score,\n",
    "    confusion_matrix)\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ParameterGrid, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/bank_marketing_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "      <th>poutcome_missing</th>\n",
       "      <th>target</th>\n",
       "      <th>pdays_contacted</th>\n",
       "      <th>has_previous_campaign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no_previous_campaign</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no_previous_campaign</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no_previous_campaign</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no_previous_campaign</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no_previous_campaign</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  campaign  pdays  previous              poutcome   y  \\\n",
       "0  unknown    5   may         1     -1         0  no_previous_campaign  no   \n",
       "1  unknown    5   may         1     -1         0  no_previous_campaign  no   \n",
       "2  unknown    5   may         1     -1         0  no_previous_campaign  no   \n",
       "3  unknown    5   may         1     -1         0  no_previous_campaign  no   \n",
       "4  unknown    5   may         1     -1         0  no_previous_campaign  no   \n",
       "\n",
       "   poutcome_missing  target  pdays_contacted  has_previous_campaign  \n",
       "0                 1       0                0                      0  \n",
       "1                 1       0                0                      0  \n",
       "2                 1       0                0                      0  \n",
       "3                 1       0                0                      0  \n",
       "4                 1       0                0                      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45195 entries, 0 to 45194\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   age                    45195 non-null  int64 \n",
      " 1   job                    45195 non-null  object\n",
      " 2   marital                45195 non-null  object\n",
      " 3   education              45195 non-null  object\n",
      " 4   default                45195 non-null  object\n",
      " 5   balance                45195 non-null  int64 \n",
      " 6   housing                45195 non-null  object\n",
      " 7   loan                   45195 non-null  object\n",
      " 8   contact                45195 non-null  object\n",
      " 9   day                    45195 non-null  int64 \n",
      " 10  month                  45195 non-null  object\n",
      " 11  campaign               45195 non-null  int64 \n",
      " 12  pdays                  45195 non-null  int64 \n",
      " 13  previous               45195 non-null  int64 \n",
      " 14  poutcome               45195 non-null  object\n",
      " 15  y                      45195 non-null  object\n",
      " 16  poutcome_missing       45195 non-null  int64 \n",
      " 17  target                 45195 non-null  int64 \n",
      " 18  pdays_contacted        45195 non-null  int64 \n",
      " 19  has_previous_campaign  45195 non-null  int64 \n",
      "dtypes: int64(10), object(10)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    39906\n",
       "1     5289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age','balance','day','campaign','pdays','previous','poutcome_missing','pdays_contacted','has_previous_campaign']\n",
    "categorical_cols = ['job','marital','education','default','housing','loan','contact','month','poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[categorical_cols + numeric_cols].copy()\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá Model Performance dựa trên 2 phương pháp xử lý class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm preprocessing khi dùng smote\n",
    "def build_tree_smote_components(cat_cols, num_cols, *, k_neighbors=5, random_state=42):\n",
    "    def clip_only(X):\n",
    "        X = X.astype(float)\n",
    "        lo = np.nanpercentile(X, 1, axis=0)\n",
    "        hi = np.nanpercentile(X, 99, axis=0)\n",
    "        return np.clip(X, lo, hi)\n",
    "\n",
    "    # PRE-SMOTE: cat -> ordinal (kỹ thuật), num -> impute + clip\n",
    "    pre_smote = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat_ord\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "            ]), cat_cols),\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"clip\", FunctionTransformer(clip_only, feature_names_out=\"one-to-one\")),\n",
    "            ]), num_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    # cat indices là [0..len(cat_cols)-1] vì cat đặt trước num\n",
    "    cat_idx = list(range(len(cat_cols)))\n",
    "\n",
    "    smote = SMOTENC(\n",
    "        categorical_features=cat_idx,\n",
    "        k_neighbors=k_neighbors,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # POST-SMOTE: onehot cat + passthrough num\n",
    "    post = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat_oh\", OneHotEncoder(handle_unknown=\"ignore\"), cat_idx),\n",
    "            (\"num_passthrough\", \"passthrough\", slice(len(cat_cols), None)),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    return pre_smote, smote, post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_smote, smote, post = build_tree_smote_components(\n",
    "    categorical_cols, numeric_cols, k_neighbors=5, random_state=42\n",
    ")\n",
    "\n",
    "clf_gb_smote = ImbPipeline(steps=[\n",
    "    (\"pre_smote\", pre_smote),\n",
    "    (\"smote\", smote),\n",
    "    (\"post\", post),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"smote__k_neighbors\": [3, 5, 7],\n",
    "    \"model__n_estimators\": randint(150, 501),      # 150..500\n",
    "    \"model__learning_rate\": uniform(0.03, 0.12),   # 0.03..0.15\n",
    "    \"model__max_depth\": [2, 3],\n",
    "    \"model__subsample\": uniform(0.6, 0.4),         # 0.6..1.0\n",
    "    \"model__min_samples_leaf\": [50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m      4\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mclf_gb_smote,\n\u001b[1;32m      5\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_score_\u001b[49m, search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=clf_gb_smote,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,                 # 25 combo -> 25*5=125 fits (nhanh hơn ~4x)\n",
    "    scoring=\"average_precision\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "print(search.best_score_, search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      7981\n",
      "           1       0.58      0.29      0.39      1058\n",
      "\n",
      "    accuracy                           0.89      9039\n",
      "   macro avg       0.74      0.63      0.66      9039\n",
      "weighted avg       0.87      0.89      0.88      9039\n",
      "\n",
      "ROC AUC: 0.7963691650467593\n",
      "Average Precision: 0.43855589925300476\n",
      "Confusion Matrix:\n",
      " [[7753  228]\n",
      " [ 749  309]]\n"
     ]
    }
   ],
   "source": [
    "best_model_smote = search.best_estimator_\n",
    "\n",
    "y_pred_smote = best_model_smote.predict(X_test)\n",
    "y_proba_smote = best_model_smote.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_smote))\n",
    "print(\"Average Precision:\", average_precision_score(y_test, y_proba_smote))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocess_tree(cat_cols, num_cols):\n",
    "    def clip_only(X):\n",
    "        X = X.astype(float)\n",
    "        lo = np.nanpercentile(X, 1, axis=0)\n",
    "        hi = np.nanpercentile(X, 99, axis=0)\n",
    "        return np.clip(X, lo, hi)\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\",\n",
    "             Pipeline([\n",
    "                 (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                 (\"clip\", FunctionTransformer(clip_only, feature_names_out=\"one-to-one\")),\n",
    "             ]),\n",
    "             num_cols),\n",
    "            (\"cat\",\n",
    "             Pipeline([\n",
    "                 (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                 (\"oh\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "             ]),\n",
    "             cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        \"model__n_estimators\": [200, 400],\n",
    "        \"model__learning_rate\": [0.05, 0.1],\n",
    "        \"model__max_depth\": [2, 3],\n",
    "        \"model__subsample\": [0.7, 0.9],\n",
    "        \"model__min_samples_leaf\": [50, 100]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight:\n",
    "pre_tree = make_preprocess_tree(categorical_cols, numeric_cols)\n",
    "\n",
    "clf_gb_cw = Pipeline(steps=[\n",
    "    (\"prep\", pre_tree),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     16\u001b[0m sw_tr \u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_tr)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel__sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msw_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_va)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend(average_precision_score(y_va, proba))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    662\u001b[0m         )\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:787\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:883\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    876\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    877\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    878\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    879\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    880\u001b[0m         )\n\u001b[1;32m    882\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:489\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    486\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    488\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 489\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    494\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/tree/_classes.py:1404\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1404\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    scores = []\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "        y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "        model = clone(clf_gb_cw)\n",
    "        model.set_params(**params)\n",
    "\n",
    "        sw_tr = compute_sample_weight(\"balanced\", y_tr)\n",
    "        model.fit(X_tr, y_tr, model__sample_weight=sw_tr)\n",
    "\n",
    "        proba = model.predict_proba(X_va)[:, 1]\n",
    "        scores.append(average_precision_score(y_va, proba))\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST CV PR-AUC: 0.4511\n",
      "BEST PARAMS: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 50, 'model__n_estimators': 400, 'model__subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "print(f\"BEST CV PR-AUC: {best_score:.4f}\")\n",
    "print(f\"BEST PARAMS: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_samples_leaf\": 50,\n",
    "    \"n_estimators\": 400,\n",
    "    \"subsample\": 0.9,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'learning_rate' for estimator Pipeline(steps=[('prep',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imp',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('clip',\n                                                                   FunctionTransformer(feature_names_out='one-to-one',\n                                                                                       func=<function make_preprocess_tree.<locals>.clip_only at 0x17b4f1f30>))]),\n                                                  ['age', 'balance', 'day',\n                                                   'campaign', 'pdays',\n                                                   'previous',\n                                                   'poutcome_missing',\n                                                   'pdays_contacted',\n                                                   'has_previous_campaign']),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imp',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('oh',\n                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n                                                  ['job', 'marital',\n                                                   'education', 'default',\n                                                   'housing', 'loan', 'contact',\n                                                   'month', 'poutcome'])])),\n                ('model', GradientBoostingClassifier(random_state=42))]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m clone(clf_gb_cw)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sw_full \u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train)\n\u001b[1;32m      6\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      7\u001b[0m     X_train,\n\u001b[1;32m      8\u001b[0m     y_train,\n\u001b[1;32m      9\u001b[0m     model__sample_weight\u001b[38;5;241m=\u001b[39msw_full\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/pipeline.py:319\u001b[0m, in \u001b[0;36mPipeline.set_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the parameters of this estimator.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    Valid parameter keys can be listed with ``get_params()``. Note that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m        Pipeline class instance.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:69\u001b[0m, in \u001b[0;36m_BaseComposition._set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace_estimator(attr, name, params\u001b[38;5;241m.\u001b[39mpop(name))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 3. Step parameters and other initialisation arguments\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf310/lib/python3.10/site-packages/sklearn/base.py:345\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[1;32m    344\u001b[0m     local_valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[1;32m    351\u001b[0m     nested_params[key][sub_key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'learning_rate' for estimator Pipeline(steps=[('prep',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imp',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('clip',\n                                                                   FunctionTransformer(feature_names_out='one-to-one',\n                                                                                       func=<function make_preprocess_tree.<locals>.clip_only at 0x17b4f1f30>))]),\n                                                  ['age', 'balance', 'day',\n                                                   'campaign', 'pdays',\n                                                   'previous',\n                                                   'poutcome_missing',\n                                                   'pdays_contacted',\n                                                   'has_previous_campaign']),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imp',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('oh',\n                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n                                                  ['job', 'marital',\n                                                   'education', 'default',\n                                                   'housing', 'loan', 'contact',\n                                                   'month', 'poutcome'])])),\n                ('model', GradientBoostingClassifier(random_state=42))]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose']."
     ]
    }
   ],
   "source": [
    "best_model = clone(clf_gb_cw)\n",
    "best_model.set_params(**best_params)\n",
    "\n",
    "sw_full = compute_sample_weight(\"balanced\", y_train)\n",
    "\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    model__sample_weight=sw_full\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[6666 1315]\n",
      " [ 358  700]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9490    0.8352    0.8885      7981\n",
      "           1     0.3474    0.6616    0.4556      1058\n",
      "\n",
      "    accuracy                         0.8149      9039\n",
      "   macro avg     0.6482    0.7484    0.6720      9039\n",
      "weighted avg     0.8786    0.8149    0.8378      9039\n",
      "\n",
      "ROC-AUC: 0.8053346925791856\n",
      "PR-AUC : 0.4561032146157314\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine tune mô hình bằng StratifiedKFold và ParamGrid**\n",
    "- FP = 1.315 khách hàng: Mô hình dự đoán yes nhưng thực tế là no\n",
    "- FN = 358 khách hàng: Khách có khả năng yes nhưng mô hình bỏ sót\n",
    "- Với class imbalace: \n",
    "    - Recall = 0.66: phát hiện phần lớn khách hàng tiềm năng \n",
    "    - Precision = 0.34: trade-off cho một cuộc gọi không thành công & bỏ sót khách tiềm năng\n",
    "\n",
    "Trong phạm vi đề tài, mô hình phù hợp cho việc hỗ trợ ra quyết định, giúp xếp hạng và ưu tiên danh sách khách hàng cần liên hệ trong chiến dịch telemarketing sau này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sánh kết quả của 2 phương pháp xử lý mất cân bằng dữ liệu: **Class-weight** cho ra kết quả tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá Business Performance dựa sau khi đã fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2524482 , 0.30133478, 0.40234654, ..., 0.42302173, 0.83131034,\n",
       "       0.11671982], shape=(9039,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = pd.DataFrame({\n",
    "    \"p_yes\": y_proba,\n",
    "    \"y_true\": y_test.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_yes</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.989294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>0.988273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>0.987408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>0.986030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>0.984065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_yes  y_true\n",
       "981   0.989294       1\n",
       "3520  0.988273       1\n",
       "1453  0.987408       0\n",
       "3969  0.986030       1\n",
       "5363  0.984065       1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank = df_rank.sort_values(\"p_yes\", ascending=False)\n",
    "df_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0.15\n",
    "n_top = int(len(df_rank) * K)\n",
    "\n",
    "top_k = df_rank.head(n_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.44206642066420665)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CR_model = top_k[\"y_true\"].mean()\n",
    "CR_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Trong **15% khách hàng** được ưu tiên gọi, **44% thực sự đồng ý** (yes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lift @ 15%: 3.78\n"
     ]
    }
   ],
   "source": [
    "CR_random = df_rank[\"y_true\"].mean()\n",
    "lift = CR_model / CR_random\n",
    "print(f\"Lift @ {K*100:.0f}%: {lift:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So với chiến lược gọi ngẫu nhiên, mô hình giúp **tăng hơn 3.78 lần tỷ lệ chuyển đổi** khi chỉ tập trung vào 30% khách hàng tiềm năng nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả cho thấy mô hình mang lại hiệu quả rõ rệt. Khi chỉ tập trung vào 15% khách hàng tiềm năng nhất, tỷ lệ chuyển đổi đạt 44%, cao hơn khoảng 4 lần so với tỷ lệ chuyển đổi trung bình của toàn bộ tập dữ liệu (~11–12%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def make_sample_weight(y):\n",
    "    classes = np.unique(y)\n",
    "    cw = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=classes,\n",
    "        y=y\n",
    "    )\n",
    "    class_weight_dict = dict(zip(classes, cw))\n",
    "    return np.array([class_weight_dict[yi] for yi in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting | TEST PR-AUC: 0.4561032146157314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import average_precision_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "BEST_PARAMS = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_samples_leaf\": 50,\n",
    "    \"n_estimators\": 400,\n",
    "    \"subsample\": 0.9,\n",
    "}\n",
    "\n",
    "numeric_cols = ['age','balance','day','campaign','pdays','previous','poutcome_missing','pdays_contacted','has_previous_campaign']\n",
    "categorical_cols = ['job','marital','education','default','housing','loan','contact','month','poutcome']\n",
    "\n",
    "gb_clf = Pipeline(steps=[\n",
    "    (\"prep\", make_preprocess_tree(categorical_cols, numeric_cols)),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        learning_rate=BEST_PARAMS[\"learning_rate\"],\n",
    "        max_depth=BEST_PARAMS[\"max_depth\"],\n",
    "        min_samples_leaf=BEST_PARAMS[\"min_samples_leaf\"],\n",
    "        n_estimators=BEST_PARAMS[\"n_estimators\"],\n",
    "        subsample=BEST_PARAMS[\"subsample\"],\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "sample_weight = make_sample_weight(y_train)\n",
    "\n",
    "gb_clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    model__sample_weight=sample_weight\n",
    ")\n",
    "\n",
    "y_proba = gb_clf.predict_proba(X_test)[:, 1]\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "print(\"Gradient Boosting | TEST PR-AUC:\", pr_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting | TEST PR-AUC: 0.4561032146157314\n",
      "Threshold default: 0.500\n",
      "Threshold by call_budget=10%: 0.738337 (top 904 samples)\n",
      "\n",
      "=== Default 0.5 | thr=0.500000 ===\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      " [[6666 1315]\n",
      " [ 358  700]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9490    0.8352    0.8885      7981\n",
      "           1     0.3474    0.6616    0.4556      1058\n",
      "\n",
      "    accuracy                         0.8149      9039\n",
      "   macro avg     0.6482    0.7484    0.6720      9039\n",
      "weighted avg     0.8786    0.8149    0.8378      9039\n",
      "\n",
      "\n",
      "=== Call budget 10% | thr=0.738337 ===\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      " [[7542  439]\n",
      " [ 593  465]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9271    0.9450    0.9360      7981\n",
      "           1     0.5144    0.4395    0.4740      1058\n",
      "\n",
      "    accuracy                         0.8858      9039\n",
      "   macro avg     0.7207    0.6923    0.7050      9039\n",
      "weighted avg     0.8788    0.8858    0.8819      9039\n",
      "\n",
      "\n",
      "#Errors at thr=0.5\n",
      "FN count: 358 | FP count: 1315 | Total: 9039\n",
      "\n",
      "=== Hard False Negatives (missed conversions) ===\n",
      " age  balance  day  campaign  pdays  previous  poutcome_missing  pdays_contacted  has_previous_campaign           job  marital education default housing loan  contact month             poutcome  y_true  y_pred_05  y_proba\n",
      "  57       63   25        17     -1         0                 1                0                      0       retired divorced   primary      no      no  yes cellular   jul no_previous_campaign       1          0 0.075975\n",
      "  44     -156   30         2     -1         0                 1                0                      0     housemaid  married   primary      no      no  yes cellular   jul no_previous_campaign       1          0 0.083270\n",
      "  53      104    5         1     -1         0                 1                0                      0     housemaid  married   primary      no      no  yes  unknown   jun no_previous_campaign       1          0 0.088514\n",
      "  59      -22   26         3     -1         0                 1                0                      0      services  married secondary      no     yes   no  unknown   may no_previous_campaign       1          0 0.092389\n",
      "  53     -291    7         1     -1         0                 1                0                      0      services divorced   primary      no     yes  yes  unknown   may no_previous_campaign       1          0 0.096361\n",
      "  41     -306   15         1     -1         0                 1                0                      0        admin.  married   primary      no     yes   no  unknown   may no_previous_campaign       1          0 0.100612\n",
      "  49     -157    7         3     -1         0                 1                0                      0   blue-collar  married   primary      no     yes   no cellular   jul no_previous_campaign       1          0 0.105097\n",
      "  57        0   28         1     -1         0                 1                0                      0       retired  married  tertiary      no     yes  yes  unknown   may no_previous_campaign       1          0 0.108650\n",
      "  55     2152   19         2     -1         0                 1                0                      0     housemaid  married   primary      no      no   no  unknown   jun no_previous_campaign       1          0 0.111337\n",
      "  30     -617   19         1     -1         0                 1                0                      0 self-employed   single secondary      no      no  yes cellular   nov no_previous_campaign       1          0 0.112838\n",
      "  53     -462   29         1     -1         0                 1                0                      0   blue-collar  married   primary     yes      no   no cellular   jan no_previous_campaign       1          0 0.116720\n",
      "  57     9103   20         2     -1         0                 1                0                      0    management  married  tertiary      no      no  yes  unknown   jun no_previous_campaign       1          0 0.118264\n",
      "  29      199    7         4     -1         0                 1                0                      0    management  married  tertiary      no     yes  yes  unknown   may no_previous_campaign       1          0 0.127158\n",
      "  31      792   20        14     -1         0                 1                0                      0    management  married  tertiary      no      no   no cellular   aug no_previous_campaign       1          0 0.128221\n",
      "  35     1055   18         2     -1         0                 1                0                      0   blue-collar  married secondary      no      no   no  unknown   nov no_previous_campaign       1          0 0.130956\n",
      "\n",
      "=== Hard False Positives (wasted calls) ===\n",
      " age  balance  day  campaign  pdays  previous  poutcome_missing  pdays_contacted  has_previous_campaign           job marital education default housing loan   contact month poutcome  y_true  y_pred_05  y_proba\n",
      "  30       53   30         1    184         1                 0                1                      1    technician  single  tertiary      no      no   no  cellular   oct  success       0          1 0.987408\n",
      "  44    11115   25         1    185         4                 0                1                      1    technician  single   unknown      no      no   no  cellular   oct  success       0          1 0.982176\n",
      "  50     8205   25         3    508         1                 0                1                      1    management married  tertiary      no     yes   no telephone   oct    other       0          1 0.979398\n",
      "  41    10346   14         1    182         3                 0                1                      1 self-employed  single  tertiary      no      no   no  cellular   dec  success       0          1 0.973906\n",
      "  33      506    4         1     91         2                 0                1                      1    management  single  tertiary      no      no   no  cellular   jun  success       0          1 0.971234\n",
      "  34      215    5         1     94         3                 0                1                      1   blue-collar  single secondary      no      no   no  cellular   jun  success       0          1 0.970279\n",
      "  46     2671   13         3     91         4                 0                1                      1    management married  tertiary      no      no   no  cellular   nov  success       0          1 0.970024\n",
      "  62     4608   14         1    186         1                 0                1                      1        admin. married secondary      no      no   no  cellular   sep  success       0          1 0.969630\n",
      "  73      508   14         4     97         1                 0                1                      1       retired married   primary      no      no   no  cellular   jun  success       0          1 0.966900\n",
      "  69      324   12         1    189         4                 0                1                      1       retired married   primary      no      no   no  cellular   aug  success       0          1 0.966708\n",
      "  31      270   16         1    200         2                 0                1                      1        admin.  single secondary      no      no   no  cellular   nov  success       0          1 0.965987\n",
      "  28     1633    8         1     95         1                 0                1                      1    management  single secondary      no      no   no  cellular   sep  success       0          1 0.965073\n",
      "  62     2917   12         1    188         1                 0                1                      1       retired married secondary      no      no   no  cellular   apr  success       0          1 0.964744\n",
      "  42      406    8         1    391         2                 0                1                      1    management married secondary      no     yes   no  cellular   jul  success       0          1 0.962854\n",
      "  31     1599   30         1     78         2                 0                1                      1      services  single secondary      no      no   no  cellular   apr  success       0          1 0.962343\n",
      "\n",
      "=== Top error groups by job (n>=50) ===\n",
      "               err_rate     n\n",
      "job                          \n",
      "student        0.412322   211\n",
      "retired        0.309524   462\n",
      "unemployed     0.268398   231\n",
      "self-employed  0.231003   329\n",
      "management     0.225977  1894\n",
      "admin.         0.197907  1051\n",
      "technician     0.165803  1544\n",
      "entrepreneur   0.140468   299\n",
      "housemaid      0.128319   226\n",
      "services       0.125436   861\n",
      "\n",
      "=== Top error groups by month (n>=50) ===\n",
      "       err_rate     n\n",
      "month                \n",
      "oct    0.520833   144\n",
      "sep    0.455285   123\n",
      "mar    0.430108    93\n",
      "apr    0.340187   535\n",
      "feb    0.291005   567\n",
      "aug    0.231445  1253\n",
      "jul    0.161290  1364\n",
      "jan    0.159722   288\n",
      "jun    0.136282  1108\n",
      "nov    0.131643   828\n",
      "\n",
      "=== Top error groups by contact (n>=50) ===\n",
      "           err_rate     n\n",
      "contact                  \n",
      "cellular   0.250687  5820\n",
      "telephone  0.179130   575\n",
      "unknown    0.041982  2644\n",
      "\n",
      "=== Top error groups by poutcome (n>=50) ===\n",
      "                      err_rate     n\n",
      "poutcome                            \n",
      "success               0.343333   300\n",
      "other                 0.288889   360\n",
      "failure               0.240759  1001\n",
      "no_previous_campaign  0.166034  7378\n",
      "\n",
      "=== Top error groups by education (n>=50) ===\n",
      "           err_rate     n\n",
      "education                \n",
      "tertiary   0.251992  2635\n",
      "unknown    0.172973   370\n",
      "secondary  0.163074  4685\n",
      "primary    0.134173  1349\n",
      "\n",
      "=== Top error groups by marital (n>=50) ===\n",
      "          err_rate     n\n",
      "marital                 \n",
      "single    0.279645  2589\n",
      "divorced  0.198650  1037\n",
      "married   0.137262  5413\n",
      "\n",
      "=== Top error groups by housing (n>=50) ===\n",
      "         err_rate     n\n",
      "housing                \n",
      "no       0.265078  4112\n",
      "yes      0.118328  4927\n",
      "\n",
      "=== Top error groups by loan (n>=50) ===\n",
      "      err_rate     n\n",
      "loan                \n",
      "no    0.204160  7597\n",
      "yes   0.084605  1442\n",
      "\n",
      "=== Top error groups by default (n>=50) ===\n",
      "         err_rate     n\n",
      "default                \n",
      "no       0.186774  8861\n",
      "yes      0.101124   178\n",
      "\n",
      "thr=0.20 | precision=0.1409 | recall=0.9452 | FP=6097 | FN=58 | TP=1000\n",
      "\n",
      "thr=0.30 | precision=0.1835 | recall=0.8459 | FP=3983 | FN=163 | TP=895\n",
      "\n",
      "thr=0.40 | precision=0.2575 | recall=0.7571 | FP=2310 | FN=257 | TP=801\n",
      "\n",
      "thr=0.50 | precision=0.3474 | recall=0.6616 | FP=1315 | FN=358 | TP=700\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "# ====== Predict & PR-AUC ======\n",
    "y_proba = gb_clf.predict_proba(X_test)[:, 1]\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "print(\"Gradient Boosting | TEST PR-AUC:\", pr_auc)\n",
    "\n",
    "# ====== Choose threshold (default 0.5 + option theo call_budget) ======\n",
    "thr_default = 0.5\n",
    "\n",
    "# Nếu bạn có call_budget (vd 10%), chọn ngưỡng để chỉ gọi top K%\n",
    "call_budget = 0.10  # chỉnh theo bài của bạn\n",
    "k = int(np.ceil(call_budget * len(y_proba)))\n",
    "thr_budget = np.sort(y_proba)[-k] if k > 0 else 1.0\n",
    "\n",
    "print(f\"Threshold default: {thr_default:.3f}\")\n",
    "print(f\"Threshold by call_budget={call_budget:.0%}: {thr_budget:.6f} (top {k} samples)\")\n",
    "\n",
    "def eval_at_threshold(thr: float, name: str):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n=== {name} | thr={thr:.6f} ===\")\n",
    "    print(\"Confusion matrix [ [TN FP], [FN TP] ]:\\n\", cm)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    return y_pred, cm\n",
    "\n",
    "y_pred_05, cm_05 = eval_at_threshold(thr_default, \"Default 0.5\")\n",
    "y_pred_b, cm_b = eval_at_threshold(thr_budget, f\"Call budget {call_budget:.0%}\")\n",
    "\n",
    "# ====== Build error table to inspect bad cases ======\n",
    "err = X_test.copy()\n",
    "err = err.reset_index(drop=True)\n",
    "err[\"y_true\"] = np.array(y_test)\n",
    "err[\"y_proba\"] = y_proba\n",
    "err[\"y_pred_05\"] = y_pred_05\n",
    "err[\"is_error_05\"] = (err[\"y_true\"] != err[\"y_pred_05\"]).astype(int)\n",
    "\n",
    "fn = err[(err[\"y_true\"] == 1) & (err[\"y_pred_05\"] == 0)].copy()\n",
    "fp = err[(err[\"y_true\"] == 0) & (err[\"y_pred_05\"] == 1)].copy()\n",
    "\n",
    "print(\"\\n#Errors at thr=0.5\")\n",
    "print(\"FN count:\", len(fn), \"| FP count:\", len(fp), \"| Total:\", len(err))\n",
    "\n",
    "\n",
    "fn_hard = fn.sort_values(\"y_proba\", ascending=True).head(15)\n",
    "# FP “nặng”: model rất tự tin là 1 (proba cao) nhưng thực tế là 0\n",
    "fp_hard = fp.sort_values(\"y_proba\", ascending=False).head(15)\n",
    "\n",
    "cols_show = (numeric_cols + categorical_cols)\n",
    "cols_show = [c for c in cols_show if c in err.columns]  # an toàn nếu thiếu cột engineered\n",
    "\n",
    "print(\"\\n=== Hard False Negatives (missed conversions) ===\")\n",
    "print(fn_hard[cols_show + [\"y_true\", \"y_pred_05\", \"y_proba\"]].to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Hard False Positives (wasted calls) ===\")\n",
    "print(fp_hard[cols_show + [\"y_true\", \"y_pred_05\", \"y_proba\"]].to_string(index=False))\n",
    "def error_by(col):\n",
    "    if col not in err.columns:\n",
    "        return None\n",
    "    g = (err.groupby(col)[\"is_error_05\"]\n",
    "         .agg(err_rate=\"mean\", n=\"size\")\n",
    "         .sort_values([\"err_rate\", \"n\"], ascending=[False, False]))\n",
    "    return g\n",
    "\n",
    "group_cols = [\"job\", \"month\", \"contact\", \"poutcome\", \"education\", \"marital\", \"housing\", \"loan\", \"default\"]\n",
    "for c in group_cols:\n",
    "    g = error_by(c)\n",
    "    if g is None:\n",
    "        continue\n",
    "    g2 = g[g[\"n\"] >= 50].head(10)\n",
    "    print(f\"\\n=== Top error groups by {c} (n>=50) ===\")\n",
    "    print(g2.to_string())\n",
    "\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
    "for t in [0.2, 0.3, 0.4, 0.5]:\n",
    "    yp = (y_proba >= t).astype(int)\n",
    "    cm = confusion_matrix(y_test, yp)\n",
    "    tn, fp_, fn_, tp = cm.ravel()\n",
    "    p = tp / (tp + fp_ + 1e-12)\n",
    "    r = tp / (tp + fn_ + 1e-12)\n",
    "    print(f\"\\nthr={t:.2f} | precision={p:.4f} | recall={r:.4f} | FP={fp_} | FN={fn_} | TP={tp}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
